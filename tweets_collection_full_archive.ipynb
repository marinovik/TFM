{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Unificado2 - Nat y MJ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.0 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importamos librerías"
      ],
      "metadata": {
        "id": "NS80kz2SsClE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import os\n",
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import openpyxl"
      ],
      "outputs": [],
      "metadata": {
        "id": "36fgHz-Qr7nW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72714274-429e-48c6-9edf-3ae2fca78522"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Credenciales para el uso de la API\n"
      ],
      "metadata": {
        "id": "ugBpSobvsMEP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "consumer_key= 'qLBuvGr2AzL5TmARGF2vIYLar'\n",
        "consumer_secret= 'WwPMJxsf7ofyYLsqEr1Tj8dy636eT9D5Jmgp4ab2JgjT5RpQJo'\n",
        "access_token= '1267192889416847362-4WE0cPAp56rWJ7sGedH909p8QC4P0v'\n",
        "access_token_secret= 'ByZnnbxuiRoBNbfoWJTCj6xiXuwCwoLorwVOOfZPD44ln'"
      ],
      "outputs": [],
      "metadata": {
        "id": "pQNk2jW8sPAw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "N_YulbAEsSaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funcion que genere fechas-horas aleatorias \n",
        "- El rango será entre el 1 de enero de 2020 y el 15 de julio de 2021\n",
        "- Se generará una fecha y esta será el parámetro *toDate*\n",
        "- Se aleatorizará de la siguiente manera:\n",
        "    · año -> 2020 o 2021\\\n",
        "    · mes:\\\n",
        "        >>> si año = 2020 -> aleatorio de 1 a 12\\\n",
        "        >>> si año = 2021 -> aleatorio de 1 a 7\\\n",
        "    · dia:\\\n",
        "           >>>  si mes = 1 / 3 / 5 / 7 / 8 / 10 / 12 -> aleatorio de 1 a 31\\\n",
        "           >>>  si mes = 4 / 6 / 9 / 11 -> aleatorio de 1 a 30\\\n",
        "           >>>  si mes = 2 -> aleatorio de 1 a 28\\\n",
        "    · hora -> de 0 a 24\\\n",
        "    · minutos -> constante a 00"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "def generate_toDate():\n",
        "\n",
        "    # Generar año\n",
        "    year =  str(np.random.choice([2020, 2021]))\n",
        "\n",
        "    # Generar mes\n",
        "    if year == '2020':\n",
        "        month = str(np.random.randint(low=1, high=12))\n",
        "    else:\n",
        "        month = str(np.random.randint(low=1, high=7))\n",
        "    if len(month) == 1: month = '0' + month\n",
        "    \n",
        "    # Generar dia\n",
        "    if month in ['01', '03', '05', '07', '08', '10', '12']:\n",
        "        day = str(np.random.randint(low=1, high=31))\n",
        "    elif month in ['04', '06', '09', '11']:\n",
        "        day = str(np.random.randint(low=1, high=30))\n",
        "    else:\n",
        "        day = str(np.random.randint(low=1, high=28))\n",
        "    if len(day) == 1: day = '0' + day\n",
        "\n",
        "    # Generar hora\n",
        "    hour = str(np.random.randint(low=0, high=24))\n",
        "    if len(hour) == 1: hour = '0' + hour\n",
        "\n",
        "    \n",
        "    toDate = year + month + day + hour + '00'\n",
        "\n",
        "    return toDate"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXTRACCION FULL ARCHIVE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "query_word = 'telefonica OR movistar'\n",
        "until = '202103281200'"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "source": [
        "x = api.search_full_archive(environment_name='fullarchive', query=query_word,\n",
        "                            toDate=until, maxResults=100)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "def tweets_to_DF(tweets):\n",
        "    \n",
        "    df=pd.DataFrame(columns=['tweet_id', 'text', 'created_at', 'retweeted', 'retweet_count', 'favorite_count','user_ verified',\n",
        "                             'user_id', 'user_name', 'user_location', 'geo', 'coordinates', 'place', 'user_notificacion', \n",
        "                             'user_followers', 'user_friends','user_withheld_in_countries', 'is_reply', 'finished_tweet',\n",
        "                             'status_count'])    \n",
        "    i=0\n",
        "    for tweet in tweets:\n",
        "\n",
        "        new_row = {\n",
        "        'tweet_id': tweet._json['id'],\n",
        "        'text': tweet._json['text'],\n",
        "        'created_at': tweet._json['created_at'],\n",
        "        'retweeted': tweet._json['retweeted'],\n",
        "        'retweet_count': tweet._json['retweet_count'],\n",
        "        'favorite_count': tweet._json['favorite_count'],\n",
        "        'user_verified': tweet._json['user']['verified'], \n",
        "        'user_id': tweet._json['user']['id'],\n",
        "        'user_name': tweet._json['user']['screen_name'],\n",
        "        'user_location': tweet._json['user']['location'],\n",
        "        'geo': tweet._json['geo'],\n",
        "        'coordinates': tweet._json['coordinates'],\n",
        "        'place': tweet._json['place'],\n",
        "        'user_notificacion': tweet._json['user']['notifications'],\n",
        "        'user_followers': tweet._json['user']['followers_count'],\n",
        "        'user_friends': tweet._json['user']['friends_count'],\n",
        "        'user_withheld_in_countries':  tweet._json['user']['withheld_in_countries'],\n",
        "        'is_reply': tweet._json['in_reply_to_status_id'],\n",
        "        'finished_tweet': tweet._json['truncated'],\n",
        "        'status_count':tweet._json['user']['statuses_count']\n",
        "        }\n",
        "        \n",
        "        df.loc[i] = new_row # Añadimos la info al dataframe en una nueva fila\n",
        "        i = i + 1\n",
        "\n",
        "    return df\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANTE!\n",
        "Cada vez que se haga una extracción, crear un nuevo dataframe y guardarlo en excel de la siguiente manera: \\\n",
        "\\\n",
        "    *df_fa_x = tweets_to_DF(x)* \\\n",
        "    *df_fa_x.to_excel('extracciones/df_fa_x.xlsx')* \\\n",
        "    \\\n",
        "**Sustituir 'x' por un número siguiendo una numeración consecutiva**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "source": [
        "df_fa_1 = tweets_to_DF(x)\n",
        "df_fa_1.to_excel('extracciones/df_fa_1.xlsx')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combinar DataFrames con las extracciones de prueba. Con esto se conforma el dataframe al que se le irán añadiendo las futuras extracciones:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "df_fa_1 = pd.read_excel('extracciones/df_fa_1.xlsx')\n",
        "df_fa_2 = pd.read_excel('extracciones/df_fa_2.xlsx')\n",
        "df_fa_3 = pd.read_excel('extracciones/df_fa_3.xlsx')\n",
        "df_fa_4 = pd.read_excel('extracciones/df_fa_4.xlsx')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "#NO VOLVER A EJECUTAR\n",
        "df_fa = df_fa_1.append(df_fa_2, ignore_index=True)\n",
        "df_fa = df_fa.append(df_fa_3, ignore_index=True)\n",
        "df_fa = df_fa.append(df_fa_4, ignore_index=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bucle para automatizar la extraccion con las siguientes operaciones:\n",
        "- Obtener *toDate* aleatoria\n",
        "- Ejecutar *api.search_full_archive*\n",
        "- Generar dataframe a partir de los tweets extraidos\n",
        "- Guardar extraccion en excel\n",
        "- Añadir extraccion a DataFrame conjunto *df_fa*\n",
        "\n",
        "## IMPORTANTE: Por seguridad, al acabar un bucle, guardamos *df_fa* en excel"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANTISIMO: Antes de ejecutar el bucle, asegurarse que df_fa está cargado con todas las extracciones y revisar que n en 'str(i+1+n)' que se utiliza en **'file_name'** es el correcto para que las extracciones se vayan guardando en excel con numeracion consecutiva"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "for i in range(20):\n",
        "    \n",
        "    # Obtener toDate aleatoria\n",
        "    to_date = generate_toDate()\n",
        "\n",
        "    # Ejecutar api.search_full_archive\n",
        "    x = api.search_full_archive(environment_name='fullarchive', query='telefonica OR movistar',\n",
        "                            toDate=to_date, maxResults=100)\n",
        "                            \n",
        "    # Generar dataframe a partir de los tweets extraidos\n",
        "    df_fa_n = tweets_to_DF(x)\n",
        "\n",
        "    # Guardar extraccion en excel #ACTUALIZAR NUM 30 POR NUMERO DE ARCHIVOS YA EXTRAIDOS!!!!!\n",
        "    file_name = 'extracciones/df_fa_' + str(i+1+30) + '.xlsx'\n",
        "    df_fa_n.to_excel(file_name)\n",
        "\n",
        "    # Añadir extraccion al DataFrame conjunto 'df_fa'\n",
        "    df_fa = df_fa.append(df_fa_n, ignore_index=True)\n",
        "\n",
        "    \n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardado de el df conjunto por seguridad.\\\n",
        "*No olvidarse de modificar el nombre del archivo: extracciones/df_fa_v**N*** siendo **N** el número de tweets totales en el DF"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "df_fa.to_excel('extracciones/df_fa_v5000.xlsx')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "df_fa.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Duplicados"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "source": [
        "print(\"De la extraccion de 5000 tweets, hay {} con el mismo texto\".format(df_fa.duplicated(subset='text', keep='first').sum()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "De la extraccion de 5000 tweets, hay 1121 con el mismo texto\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un segundo dataframe sin duplicidad de textos de tweets"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "df_fa_bu.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "df_fa_NoDup = df_fa.drop_duplicates(subset='text', keep=\"last\") # keep='last' para tratar de quedarnos con el tweet original"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "source": [
        "df_fa_NoDup.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0             tweet_id  \\\n",
              "1         1.0  1344793731602525952   \n",
              "2         2.0  1344793519911742976   \n",
              "3         3.0  1344793498139169024   \n",
              "5         5.0  1344792735497256960   \n",
              "6         6.0  1344792136361849088   \n",
              "\n",
              "                                                text  \\\n",
              "1  @Olty86 @cerquami No dai è la mia compagnia te...   \n",
              "2  @TELMEXSoluciona urgeeeee ayuda! Estoy sin Int...   \n",
              "3  @Ticketmaster_Me la línea telefónica, la págin...   \n",
              "5  RT @PtelefonicaCol: Diciembre #En2020 @Movista...   \n",
              "6                            https://t.co/pHOp04G6DH   \n",
              "\n",
              "                       created_at retweeted retweet_count favorite_count  \\\n",
              "1  Thu Dec 31 23:53:05 +0000 2020     False             0              0   \n",
              "2  Thu Dec 31 23:52:14 +0000 2020     False             0              0   \n",
              "3  Thu Dec 31 23:52:09 +0000 2020     False             0              0   \n",
              "5  Thu Dec 31 23:49:07 +0000 2020     False             0              0   \n",
              "6  Thu Dec 31 23:46:44 +0000 2020     False             0              0   \n",
              "\n",
              "   user_ verified             user_id        user_name  ...  geo coordinates  \\\n",
              "1             NaN          1575466218        Mottalemi  ...  NaN         NaN   \n",
              "2             NaN           115687940     ilseivonsita  ...  NaN         NaN   \n",
              "3             NaN           329952390      jc_becerril  ...  NaN         NaN   \n",
              "5             NaN  946049228572372992  MovistarArenaCo  ...  NaN         NaN   \n",
              "6             NaN  702878029912084480    Latertuliasps  ...  NaN         NaN   \n",
              "\n",
              "  place user_notificacion  user_followers user_friends  \\\n",
              "1   NaN               NaN            3918          570   \n",
              "2   NaN               NaN             210          501   \n",
              "3   NaN               NaN             102          345   \n",
              "5   NaN               NaN           22703          371   \n",
              "6   NaN               NaN             399          117   \n",
              "\n",
              "  user_withheld_in_countries               is_reply finished_tweet  \\\n",
              "1                         []  1344793484348301056.0          False   \n",
              "2                         []                    NaN          False   \n",
              "3                         []                    NaN           True   \n",
              "5                         []                    NaN          False   \n",
              "6                         []                    NaN          False   \n",
              "\n",
              "  status_count  \n",
              "1        73339  \n",
              "2        10164  \n",
              "3         2131  \n",
              "5         3033  \n",
              "6         9871  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>user_ verified</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_name</th>\n",
              "      <th>...</th>\n",
              "      <th>geo</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>place</th>\n",
              "      <th>user_notificacion</th>\n",
              "      <th>user_followers</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_withheld_in_countries</th>\n",
              "      <th>is_reply</th>\n",
              "      <th>finished_tweet</th>\n",
              "      <th>status_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1344793731602525952</td>\n",
              "      <td>@Olty86 @cerquami No dai è la mia compagnia te...</td>\n",
              "      <td>Thu Dec 31 23:53:05 +0000 2020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1575466218</td>\n",
              "      <td>Mottalemi</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3918</td>\n",
              "      <td>570</td>\n",
              "      <td>[]</td>\n",
              "      <td>1344793484348301056.0</td>\n",
              "      <td>False</td>\n",
              "      <td>73339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1344793519911742976</td>\n",
              "      <td>@TELMEXSoluciona urgeeeee ayuda! Estoy sin Int...</td>\n",
              "      <td>Thu Dec 31 23:52:14 +0000 2020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>115687940</td>\n",
              "      <td>ilseivonsita</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>210</td>\n",
              "      <td>501</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>10164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1344793498139169024</td>\n",
              "      <td>@Ticketmaster_Me la línea telefónica, la págin...</td>\n",
              "      <td>Thu Dec 31 23:52:09 +0000 2020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>329952390</td>\n",
              "      <td>jc_becerril</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>102</td>\n",
              "      <td>345</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>2131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1344792735497256960</td>\n",
              "      <td>RT @PtelefonicaCol: Diciembre #En2020 @Movista...</td>\n",
              "      <td>Thu Dec 31 23:49:07 +0000 2020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>946049228572372992</td>\n",
              "      <td>MovistarArenaCo</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22703</td>\n",
              "      <td>371</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>3033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1344792136361849088</td>\n",
              "      <td>https://t.co/pHOp04G6DH</td>\n",
              "      <td>Thu Dec 31 23:46:44 +0000 2020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>702878029912084480</td>\n",
              "      <td>Latertuliasps</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>399</td>\n",
              "      <td>117</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>9871</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardamos el dataframe sin duplicados en un excel para proceder con el etiquetado:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "source": [
        "df_fa_NoDup.to_excel('extracciones\\df_fa_v5000_NoDup.xlsx')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}