{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Conexion a la API de IBM Watson"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "nlu_apikey = \"rEtSCvVcgGzc0J52bopcij525C2VBT5aOa2L2Qn4Y8-o\"\n",
    "nlu_url = \"https://api.eu-de.natural-language-understanding.watson.cloud.ibm.com/instances/fba99f47-a59f-43b1-b9b3-cf2b89e046cf\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CREDENCIALES API IBM - MARIO\n",
    "{ \\\n",
    "  \"apikey\": \"rEtSCvVcgGzc0J52bopcij525C2VBT5aOa2L2Qn4Y8-o\", \\\n",
    "  \"iam_apikey_description\": \"Auto-generated for key 2c8ee236-7b25-4d41-b0d5-b6f628a882c4\", \\\n",
    "  \"iam_apikey_name\": \"Auto-generated service credentials\", \\\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Manager\", \\\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/c1eefd8c53d94ef180c679051a5b025c::serviceid:ServiceId-b6d2b06c-54cf-4fb1-9767-2113be5f6240\", \\\n",
    "  \"url\": \"https://api.eu-de.natural-language-understanding.watson.cloud.ibm.com/instances/fba99f47-a59f-43b1-b9b3-cf2b89e046cf\" \\\n",
    "}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, CategoriesOptions, ConceptsOptions, EmotionOptions, EntitiesOptions, KeywordsOptions, RelationsOptions, SentimentOptions\n",
    "\n",
    "authenticator = IAMAuthenticator(nlu_apikey)\n",
    "natural_language_undestanding = NaturalLanguageUnderstandingV1(\n",
    "    version = '2020-08-01', \n",
    "    authenticator = authenticator\n",
    ")\n",
    "natural_language_undestanding.set_service_url(nlu_url)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importar dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('full-data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  \\\n",
       "0              0             0   \n",
       "1              1             1   \n",
       "2              2             2   \n",
       "3              3             3   \n",
       "4              4             4   \n",
       "...          ...           ...   \n",
       "7804        7804          7804   \n",
       "7805        7805          7805   \n",
       "7806        7806          7806   \n",
       "7807        7807          7807   \n",
       "7808        7808          7808   \n",
       "\n",
       "                                                   text  created_at  \\\n",
       "0     @Uber_Support hi guys why all my trips this we...  Wed Aug 11   \n",
       "1     So are we getting Uber eats league 1 or not @S...  Wed Aug 11   \n",
       "2     @footballdaily 2-3 years of Messi, a bit of ca...  Wed Aug 11   \n",
       "3     @Prashan32439454 @Uber_Support @rameshjoshi80 ...  Wed Aug 11   \n",
       "4     Uber's Gopuff partnership, Drizly deal being p...  Wed Aug 11   \n",
       "...                                                 ...         ...   \n",
       "7804  Over 3,800 rides in over 3.5 years one blown t...  Mon Aug 09   \n",
       "7805  @CoolABADev obviously i will want Messi to suc...  Mon Aug 09   \n",
       "7806  @catekitchen Shit, that’s absolutely a crap si...  Mon Aug 09   \n",
       "7807  Simply don’t take a Uber then dumb ass https:/...  Mon Aug 09   \n",
       "7808  Uber, Lyft prices keep climbing to new highs, ...  Mon Aug 09   \n",
       "\n",
       "     created_at_time  created_at_hour retweeted  retweet_count  \\\n",
       "0           09:43:42                9        Si              1   \n",
       "1           09:43:39                9        No              0   \n",
       "2           09:43:36                9        No              0   \n",
       "3           09:43:36                9        No              0   \n",
       "4           09:43:33                9        No              0   \n",
       "...              ...              ...       ...            ...   \n",
       "7804        13:01:33               13        No              0   \n",
       "7805        13:01:27               13        No              0   \n",
       "7806        13:01:24               13        No              0   \n",
       "7807        13:00:56               13        No              0   \n",
       "7808        13:00:38               13        No              0   \n",
       "\n",
       "      favorite_count  user_ verified  ...  hashtags_text hastags_indices  \\\n",
       "0                  0             NaN  ...             []              []   \n",
       "1                  0             NaN  ...             []              []   \n",
       "2                  0             NaN  ...             []              []   \n",
       "3                  0             NaN  ...             []              []   \n",
       "4                  0             NaN  ...             []              []   \n",
       "...              ...             ...  ...            ...             ...   \n",
       "7804               0             NaN  ...             []              []   \n",
       "7805               1             NaN  ...             []              []   \n",
       "7806               2             NaN  ...             []              []   \n",
       "7807               0             NaN  ...             []              []   \n",
       "7808               4             NaN  ...             []              []   \n",
       "\n",
       "     hastags_in_tweet  possitivity_textblob  possitivity_vader  \\\n",
       "0                   0              0.000000             0.0000   \n",
       "1                   0              0.000000             0.0000   \n",
       "2                   0             -0.333333             0.5859   \n",
       "3                   0              0.455000             0.4754   \n",
       "4                   0              0.000000             0.0000   \n",
       "...               ...                   ...                ...   \n",
       "7804                0              0.000000             0.4898   \n",
       "7805                0              0.114286            -0.0333   \n",
       "7806                0             -0.250000            -0.7086   \n",
       "7807                0             -0.187500            -0.8096   \n",
       "7808                0              0.136364             0.0000   \n",
       "\n",
       "      possitivity_ibm sentiment_mean  sentiment_norm     sentiment  \\\n",
       "0           -0.912398      -0.304133        0.347934      Negativo   \n",
       "1            0.000000       0.000000        0.500000        Neutro   \n",
       "2           -0.807459      -0.184964        0.407518        Neutro   \n",
       "3            0.863584       0.597995        0.798997      Positivo   \n",
       "4           -0.788377      -0.262792        0.368604      Negativo   \n",
       "...               ...            ...             ...           ...   \n",
       "7804        -0.911314      -0.140505        0.429748        Neutro   \n",
       "7805        -0.759793      -0.226269        0.386865      Negativo   \n",
       "7806        -0.988080      -0.648893        0.175553  Muy Negativo   \n",
       "7807        -0.971243      -0.656114        0.171943  Muy Negativo   \n",
       "7808         0.000000       0.045455        0.522727        Neutro   \n",
       "\n",
       "                                             categories  \n",
       "0     [{'score': 0.693098, 'label': '/travel/special...  \n",
       "1     [{'score': 0.59693, 'label': '/sports/baseball...  \n",
       "2      [{'score': 0.785107, 'label': '/sports/soccer'}]  \n",
       "3     [{'score': 0.685688, 'label': '/science/mathem...  \n",
       "4     [{'score': 0.778195, 'label': '/news'}, {'scor...  \n",
       "...                                                 ...  \n",
       "7804  [{'score': 0.998438, 'label': '/automotive and...  \n",
       "7805   [{'score': 0.780402, 'label': '/sports/soccer'}]  \n",
       "7806  [{'score': 0.841392, 'label': '/automotive and...  \n",
       "7807  [{'score': 0.60174, 'label': '/art and enterta...  \n",
       "7808  [{'score': 0.986334, 'label': '/sports/climbin...  \n",
       "\n",
       "[7809 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_at_time</th>\n",
       "      <th>created_at_hour</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_ verified</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtags_text</th>\n",
       "      <th>hastags_indices</th>\n",
       "      <th>hastags_in_tweet</th>\n",
       "      <th>possitivity_textblob</th>\n",
       "      <th>possitivity_vader</th>\n",
       "      <th>possitivity_ibm</th>\n",
       "      <th>sentiment_mean</th>\n",
       "      <th>sentiment_norm</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Uber_Support hi guys why all my trips this we...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:42</td>\n",
       "      <td>9</td>\n",
       "      <td>Si</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.912398</td>\n",
       "      <td>-0.304133</td>\n",
       "      <td>0.347934</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[{'score': 0.693098, 'label': '/travel/special...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So are we getting Uber eats league 1 or not @S...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:39</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>[{'score': 0.59693, 'label': '/sports/baseball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@footballdaily 2-3 years of Messi, a bit of ca...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:36</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>-0.807459</td>\n",
       "      <td>-0.184964</td>\n",
       "      <td>0.407518</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>[{'score': 0.785107, 'label': '/sports/soccer'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>@Prashan32439454 @Uber_Support @rameshjoshi80 ...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:36</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>0.863584</td>\n",
       "      <td>0.597995</td>\n",
       "      <td>0.798997</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[{'score': 0.685688, 'label': '/science/mathem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Uber's Gopuff partnership, Drizly deal being p...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:33</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.788377</td>\n",
       "      <td>-0.262792</td>\n",
       "      <td>0.368604</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[{'score': 0.778195, 'label': '/news'}, {'scor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804</th>\n",
       "      <td>7804</td>\n",
       "      <td>7804</td>\n",
       "      <td>Over 3,800 rides in over 3.5 years one blown t...</td>\n",
       "      <td>Mon Aug 09</td>\n",
       "      <td>13:01:33</td>\n",
       "      <td>13</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>-0.911314</td>\n",
       "      <td>-0.140505</td>\n",
       "      <td>0.429748</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>[{'score': 0.998438, 'label': '/automotive and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7805</th>\n",
       "      <td>7805</td>\n",
       "      <td>7805</td>\n",
       "      <td>@CoolABADev obviously i will want Messi to suc...</td>\n",
       "      <td>Mon Aug 09</td>\n",
       "      <td>13:01:27</td>\n",
       "      <td>13</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.759793</td>\n",
       "      <td>-0.226269</td>\n",
       "      <td>0.386865</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[{'score': 0.780402, 'label': '/sports/soccer'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>7806</td>\n",
       "      <td>7806</td>\n",
       "      <td>@catekitchen Shit, that’s absolutely a crap si...</td>\n",
       "      <td>Mon Aug 09</td>\n",
       "      <td>13:01:24</td>\n",
       "      <td>13</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.7086</td>\n",
       "      <td>-0.988080</td>\n",
       "      <td>-0.648893</td>\n",
       "      <td>0.175553</td>\n",
       "      <td>Muy Negativo</td>\n",
       "      <td>[{'score': 0.841392, 'label': '/automotive and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>7807</td>\n",
       "      <td>7807</td>\n",
       "      <td>Simply don’t take a Uber then dumb ass https:/...</td>\n",
       "      <td>Mon Aug 09</td>\n",
       "      <td>13:00:56</td>\n",
       "      <td>13</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.8096</td>\n",
       "      <td>-0.971243</td>\n",
       "      <td>-0.656114</td>\n",
       "      <td>0.171943</td>\n",
       "      <td>Muy Negativo</td>\n",
       "      <td>[{'score': 0.60174, 'label': '/art and enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7808</th>\n",
       "      <td>7808</td>\n",
       "      <td>7808</td>\n",
       "      <td>Uber, Lyft prices keep climbing to new highs, ...</td>\n",
       "      <td>Mon Aug 09</td>\n",
       "      <td>13:00:38</td>\n",
       "      <td>13</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>[{'score': 0.986334, 'label': '/sports/climbin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7809 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "dataset.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  created_at  \\\n",
       "0  @Uber_Support hi guys why all my trips this we...  Wed Aug 11   \n",
       "1  So are we getting Uber eats league 1 or not @S...  Wed Aug 11   \n",
       "2  @footballdaily 2-3 years of Messi, a bit of ca...  Wed Aug 11   \n",
       "3  @Prashan32439454 @Uber_Support @rameshjoshi80 ...  Wed Aug 11   \n",
       "4  Uber's Gopuff partnership, Drizly deal being p...  Wed Aug 11   \n",
       "\n",
       "  created_at_time  created_at_hour retweeted  retweet_count  favorite_count  \\\n",
       "0        09:43:42                9        Si              1               0   \n",
       "1        09:43:39                9        No              0               0   \n",
       "2        09:43:36                9        No              0               0   \n",
       "3        09:43:36                9        No              0               0   \n",
       "4        09:43:33                9        No              0               0   \n",
       "\n",
       "   user_ verified              user_id        user_name  ... status_count  \\\n",
       "0             NaN  1137383922843771008        ShieldVoC  ...       695888   \n",
       "1             NaN            528288653          __Soini  ...        58398   \n",
       "2             NaN            826917817          ASHJY97  ...         5974   \n",
       "3             NaN  1382729072837479936  GurmeetSinghSh6  ...          169   \n",
       "4             NaN           3646985662           sbwcws  ...       113083   \n",
       "\n",
       "   hashtags_text  hastags_indices  hastags_in_tweet possitivity_textblob  \\\n",
       "0             []               []                 0             0.000000   \n",
       "1             []               []                 0             0.000000   \n",
       "2             []               []                 0            -0.333333   \n",
       "3             []               []                 0             0.455000   \n",
       "4             []               []                 0             0.000000   \n",
       "\n",
       "   possitivity_vader possitivity_ibm sentiment_mean  sentiment_norm  sentiment  \n",
       "0             0.0000       -0.912398      -0.304133        0.347934   Negativo  \n",
       "1             0.0000        0.000000       0.000000        0.500000     Neutro  \n",
       "2             0.5859       -0.807459      -0.184964        0.407518     Neutro  \n",
       "3             0.4754        0.863584       0.597995        0.798997   Positivo  \n",
       "4             0.0000       -0.788377      -0.262792        0.368604   Negativo  \n",
       "\n",
       "[5 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_at_time</th>\n",
       "      <th>created_at_hour</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_ verified</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>...</th>\n",
       "      <th>status_count</th>\n",
       "      <th>hashtags_text</th>\n",
       "      <th>hastags_indices</th>\n",
       "      <th>hastags_in_tweet</th>\n",
       "      <th>possitivity_textblob</th>\n",
       "      <th>possitivity_vader</th>\n",
       "      <th>possitivity_ibm</th>\n",
       "      <th>sentiment_mean</th>\n",
       "      <th>sentiment_norm</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Uber_Support hi guys why all my trips this we...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:42</td>\n",
       "      <td>9</td>\n",
       "      <td>Si</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1137383922843771008</td>\n",
       "      <td>ShieldVoC</td>\n",
       "      <td>...</td>\n",
       "      <td>695888</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.912398</td>\n",
       "      <td>-0.304133</td>\n",
       "      <td>0.347934</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So are we getting Uber eats league 1 or not @S...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:39</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>528288653</td>\n",
       "      <td>__Soini</td>\n",
       "      <td>...</td>\n",
       "      <td>58398</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@footballdaily 2-3 years of Messi, a bit of ca...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:36</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>826917817</td>\n",
       "      <td>ASHJY97</td>\n",
       "      <td>...</td>\n",
       "      <td>5974</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>-0.807459</td>\n",
       "      <td>-0.184964</td>\n",
       "      <td>0.407518</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Prashan32439454 @Uber_Support @rameshjoshi80 ...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:36</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1382729072837479936</td>\n",
       "      <td>GurmeetSinghSh6</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>0.863584</td>\n",
       "      <td>0.597995</td>\n",
       "      <td>0.798997</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uber's Gopuff partnership, Drizly deal being p...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:33</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3646985662</td>\n",
       "      <td>sbwcws</td>\n",
       "      <td>...</td>\n",
       "      <td>113083</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.788377</td>\n",
       "      <td>-0.262792</td>\n",
       "      <td>0.368604</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtención del topic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def topic_ibm(tweet):\n",
    "  \n",
    "  try: \n",
    "    aux = natural_language_undestanding.analyze(text=tweet, features=Features(categories=CategoriesOptions())).get_result()['categories']\n",
    "    return aux\n",
    "  \n",
    "  except:\n",
    "    return 'Not Applicable'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset['categories'] = dataset['text'].apply(lambda x: topic_ibm(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  created_at  \\\n",
       "0  @Uber_Support hi guys why all my trips this we...  Wed Aug 11   \n",
       "1  So are we getting Uber eats league 1 or not @S...  Wed Aug 11   \n",
       "2  @footballdaily 2-3 years of Messi, a bit of ca...  Wed Aug 11   \n",
       "3  @Prashan32439454 @Uber_Support @rameshjoshi80 ...  Wed Aug 11   \n",
       "4  Uber's Gopuff partnership, Drizly deal being p...  Wed Aug 11   \n",
       "\n",
       "  created_at_time  created_at_hour retweeted  retweet_count  favorite_count  \\\n",
       "0        09:43:42                9        Si              1               0   \n",
       "1        09:43:39                9        No              0               0   \n",
       "2        09:43:36                9        No              0               0   \n",
       "3        09:43:36                9        No              0               0   \n",
       "4        09:43:33                9        No              0               0   \n",
       "\n",
       "   user_ verified              user_id        user_name  ... hashtags_text  \\\n",
       "0             NaN  1137383922843771008        ShieldVoC  ...            []   \n",
       "1             NaN            528288653          __Soini  ...            []   \n",
       "2             NaN            826917817          ASHJY97  ...            []   \n",
       "3             NaN  1382729072837479936  GurmeetSinghSh6  ...            []   \n",
       "4             NaN           3646985662           sbwcws  ...            []   \n",
       "\n",
       "   hastags_indices  hastags_in_tweet  possitivity_textblob possitivity_vader  \\\n",
       "0               []                 0              0.000000            0.0000   \n",
       "1               []                 0              0.000000            0.0000   \n",
       "2               []                 0             -0.333333            0.5859   \n",
       "3               []                 0              0.455000            0.4754   \n",
       "4               []                 0              0.000000            0.0000   \n",
       "\n",
       "   possitivity_ibm sentiment_mean sentiment_norm  sentiment  \\\n",
       "0        -0.912398      -0.304133       0.347934   Negativo   \n",
       "1         0.000000       0.000000       0.500000     Neutro   \n",
       "2        -0.807459      -0.184964       0.407518     Neutro   \n",
       "3         0.863584       0.597995       0.798997   Positivo   \n",
       "4        -0.788377      -0.262792       0.368604   Negativo   \n",
       "\n",
       "                                          categories  \n",
       "0  [{'score': 0.693098, 'label': '/travel/special...  \n",
       "1  [{'score': 0.59693, 'label': '/sports/baseball...  \n",
       "2   [{'score': 0.785107, 'label': '/sports/soccer'}]  \n",
       "3  [{'score': 0.685688, 'label': '/science/mathem...  \n",
       "4  [{'score': 0.778195, 'label': '/news'}, {'scor...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_at_time</th>\n",
       "      <th>created_at_hour</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_ verified</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtags_text</th>\n",
       "      <th>hastags_indices</th>\n",
       "      <th>hastags_in_tweet</th>\n",
       "      <th>possitivity_textblob</th>\n",
       "      <th>possitivity_vader</th>\n",
       "      <th>possitivity_ibm</th>\n",
       "      <th>sentiment_mean</th>\n",
       "      <th>sentiment_norm</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Uber_Support hi guys why all my trips this we...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:42</td>\n",
       "      <td>9</td>\n",
       "      <td>Si</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1137383922843771008</td>\n",
       "      <td>ShieldVoC</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.912398</td>\n",
       "      <td>-0.304133</td>\n",
       "      <td>0.347934</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[{'score': 0.693098, 'label': '/travel/special...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So are we getting Uber eats league 1 or not @S...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:39</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>528288653</td>\n",
       "      <td>__Soini</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>[{'score': 0.59693, 'label': '/sports/baseball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@footballdaily 2-3 years of Messi, a bit of ca...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:36</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>826917817</td>\n",
       "      <td>ASHJY97</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>-0.807459</td>\n",
       "      <td>-0.184964</td>\n",
       "      <td>0.407518</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>[{'score': 0.785107, 'label': '/sports/soccer'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Prashan32439454 @Uber_Support @rameshjoshi80 ...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:36</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1382729072837479936</td>\n",
       "      <td>GurmeetSinghSh6</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>0.863584</td>\n",
       "      <td>0.597995</td>\n",
       "      <td>0.798997</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[{'score': 0.685688, 'label': '/science/mathem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uber's Gopuff partnership, Drizly deal being p...</td>\n",
       "      <td>Wed Aug 11</td>\n",
       "      <td>09:43:33</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3646985662</td>\n",
       "      <td>sbwcws</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.788377</td>\n",
       "      <td>-0.262792</td>\n",
       "      <td>0.368604</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[{'score': 0.778195, 'label': '/news'}, {'scor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in dataset['categories'][7500]:\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'score': 0.618347, 'label': '/business and industrial/business software'}\n",
      "{'score': 0.605689, 'label': '/technology and computing/operating systems'}\n",
      "{'score': 0.58508, 'label': '/technology and computing/enterprise technology'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Guardar nuevo DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "dataset.to_csv('full-data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering con 'categories'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "pip install ast"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting ast\n",
      "  Using cached AST-0.0.2.tar.gz (19 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /usr/local/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/jt/rl_2gqv90fqbrwzlwsq9kqcm0000gn/T/pip-install-8z11b3n9/ast_186c19b6e1ef4529b01d65841fb81674/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/jt/rl_2gqv90fqbrwzlwsq9kqcm0000gn/T/pip-install-8z11b3n9/ast_186c19b6e1ef4529b01d65841fb81674/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/jt/rl_2gqv90fqbrwzlwsq9kqcm0000gn/T/pip-pip-egg-info-vpokp4yv\n",
      "         cwd: /private/var/folders/jt/rl_2gqv90fqbrwzlwsq9kqcm0000gn/T/pip-install-8z11b3n9/ast_186c19b6e1ef4529b01d65841fb81674/\n",
      "    Complete output (7 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/private/var/folders/jt/rl_2gqv90fqbrwzlwsq9kqcm0000gn/T/pip-install-8z11b3n9/ast_186c19b6e1ef4529b01d65841fb81674/setup.py\", line 6, in <module>\n",
      "        README = codecs.open(os.path.join(here, 'AST/README'), encoding='utf8').read()\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/codecs.py\", line 905, in open\n",
      "        file = builtins.open(filename, mode, buffering)\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/jt/rl_2gqv90fqbrwzlwsq9kqcm0000gn/T/pip-install-8z11b3n9/ast_186c19b6e1ef4529b01d65841fb81674/AST/README'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.23, 2.34]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('full-data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "La variable 'categories' es una lista pero al guardarse en csv, se convierte a string. Al volverlo importar, ya no podemos trabajar con ello como si fuera una lista. Para solucionarlo hay que usar la función ast.literal_eval(). Aplicarla directamente no funcionaria puesto que en algunos tweets tenemos 'Not Applicable' en lugar de una lista. Por ello se crea la siguiente función:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "def string_to_list(string):\n",
    "    from ast import literal_eval\n",
    "    try:\n",
    "        x = literal_eval(string)\n",
    "    except:\n",
    "        x = 'Not Applicable'\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "dataset['categories'] = dataset['categories'].apply(string_to_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "for cat in dataset['categories'][:20]:\n",
    "    print(cat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'score': 0.693098, 'label': '/travel/specialty travel/adventure travel'}, {'score': 0.599703, 'label': '/travel/business travel'}, {'score': 0.579002, 'label': '/automotive and vehicles'}]\n",
      "[{'score': 0.59693, 'label': '/sports/baseball'}, {'score': 0.591677, 'label': '/food and drink'}, {'score': 0.560498, 'label': '/pets/large animals'}]\n",
      "[{'score': 0.785107, 'label': '/sports/soccer'}]\n",
      "[{'score': 0.685688, 'label': '/science/mathematics/arithmetic'}, {'score': 0.602089, 'label': '/art and entertainment/shows and events'}, {'score': 0.574684, 'label': '/style and fashion/body art'}]\n",
      "[{'score': 0.778195, 'label': '/news'}, {'score': 0.647092, 'label': '/business and industrial/advertising and marketing'}, {'score': 0.609852, 'label': '/business and industrial/advertising and marketing/advertising'}]\n",
      "[{'score': 0.694885, 'label': '/society/crime/sexual offense/rape'}, {'score': 0.671184, 'label': '/society/crime/personal offense'}, {'score': 0.661246, 'label': '/society/crime/personal offense/homicide'}]\n",
      "[{'score': 0.569157, 'label': '/society/unrest and war'}, {'score': 0.564692, 'label': '/food and drink/food/snack foods'}, {'score': 0.518177, 'label': '/sports/hunting and shooting'}]\n",
      "[{'score': 0.82483, 'label': '/sports/soccer'}]\n",
      "[{'score': 0.637204, 'label': '/family and parenting/babies and toddlers/baby clothes'}, {'score': 0.631132, 'label': '/art and entertainment/shows and events'}, {'score': 0.617918, 'label': '/society/dating'}]\n",
      "[{'score': 0.647223, 'label': '/automotive and vehicles/motorcycles'}, {'score': 0.609856, 'label': '/religion and spirituality/judaism'}, {'score': 0.571212, 'label': '/technology and computing/internet technology'}]\n",
      "[{'score': 0.902669, 'label': '/sports/soccer'}]\n",
      "[{'score': 0.999379, 'label': '/technology and computing/tech news'}, {'score': 0.998862, 'label': '/technology and computing/computer reviews'}, {'score': 0.986908, 'label': '/business and industrial/business operations'}]\n",
      "[{'score': 0.678519, 'label': '/automotive and vehicles'}, {'score': 0.617486, 'label': '/automotive and vehicles/road-side assistance'}, {'score': 0.588148, 'label': '/automotive and vehicles/vehicle rental'}]\n",
      "[{'score': 0.628273, 'label': '/automotive and vehicles/vehicle rental'}, {'score': 0.585188, 'label': '/technology and computing/tech news'}, {'score': 0.549983, 'label': '/real estate/buying and selling homes'}]\n",
      "[{'score': 0.665752, 'label': '/law, govt and politics'}, {'score': 0.640749, 'label': '/society/unrest and war'}, {'score': 0.605645, 'label': '/business and industrial/business operations/business plans'}]\n",
      "[{'score': 0.688561, 'label': '/sports/bicycling/mountain biking'}, {'score': 0.557044, 'label': '/sports/climbing'}, {'score': 0.548414, 'label': '/society/dating'}]\n",
      "[{'score': 0.802466, 'label': '/health and fitness/exercise'}, {'score': 0.655227, 'label': '/automotive and vehicles/cars/car culture'}, {'score': 0.597874, 'label': '/automotive and vehicles/auto parts'}]\n",
      "[{'score': 0.585768, 'label': '/law, govt and politics/commentary'}, {'score': 0.577888, 'label': '/technology and computing/internet technology/social network'}]\n",
      "[{'score': 0.56692, 'label': '/law, govt and politics/government'}, {'score': 0.555787, 'label': '/sports/wrestling'}, {'score': 0.538234, 'label': '/law, govt and politics/government/heads of state'}]\n",
      "[{'score': 0.59787, 'label': '/automotive and vehicles/road-side assistance'}, {'score': 0.593306, 'label': '/society/gay life'}, {'score': 0.576242, 'label': '/society/unrest and war'}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Opcion 1\n",
    "Nos quedamos con la primera etiqueta de la categoría con más score. Cada tweet tendrá una única etiqueta de topic.\\\n",
    "\\\n",
    "**Ej.** [{'score': 0.693098, 'label': '/travel/specialty travel/adventure travel'}, {'score': 0.599703, 'label': '/travel/business travel'}, {'score': 0.579002, 'label': '/automotive and vehicles'}]\\\n",
    "--> **Nos quedamos con 'travel'**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "#Hacemos una copia del dataset original para trabajar con esta opcion\n",
    "dataset_1 = dataset[:100]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "def get_topic_1(categories):\n",
    "    x = categories[0]['label']\n",
    "    return x.split('/')[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "dataset_1['topic']=dataset_1['categories'].apply(lambda x: get_topic_1(x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-92-ca83377ebd66>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_1['topic']=dataset_1['categories'].apply(lambda x: get_topic_1(x))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "dataset_1[['text', 'categories', 'topic']].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  @Uber_Support hi guys why all my trips this we...   \n",
       "1  So are we getting Uber eats league 1 or not @S...   \n",
       "2  @footballdaily 2-3 years of Messi, a bit of ca...   \n",
       "3  @Prashan32439454 @Uber_Support @rameshjoshi80 ...   \n",
       "4  Uber's Gopuff partnership, Drizly deal being p...   \n",
       "\n",
       "                                          categories    topic  \n",
       "0  [{'score': 0.693098, 'label': '/travel/special...   travel  \n",
       "1  [{'score': 0.59693, 'label': '/sports/baseball...   sports  \n",
       "2   [{'score': 0.785107, 'label': '/sports/soccer'}]   sports  \n",
       "3  [{'score': 0.685688, 'label': '/science/mathem...  science  \n",
       "4  [{'score': 0.778195, 'label': '/news'}, {'scor...     news  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Uber_Support hi guys why all my trips this we...</td>\n",
       "      <td>[{'score': 0.693098, 'label': '/travel/special...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So are we getting Uber eats league 1 or not @S...</td>\n",
       "      <td>[{'score': 0.59693, 'label': '/sports/baseball...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@footballdaily 2-3 years of Messi, a bit of ca...</td>\n",
       "      <td>[{'score': 0.785107, 'label': '/sports/soccer'}]</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Prashan32439454 @Uber_Support @rameshjoshi80 ...</td>\n",
       "      <td>[{'score': 0.685688, 'label': '/science/mathem...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uber's Gopuff partnership, Drizly deal being p...</td>\n",
       "      <td>[{'score': 0.778195, 'label': '/news'}, {'scor...</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Opcion 2\n",
    "Nos quedamos con la primera etiqueta de cada categoría. \\\n",
    "\\\n",
    "**Ej.** [{'score': 0.693098, 'label': '/travel/specialty travel/adventure travel'}, {'score': 0.599703, 'label': '/travel/business travel'}, {'score': 0.579002, 'label': '/automotive and vehicles'}]\\\n",
    "--> **Nos quedamos con 'travel', 'travel' y 'automotive and vehicles** (luego eliminamos duplicados)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "#Hacemos una copia del dataset original para trabajar con esta opcion\n",
    "dataset_2 = dataset[:100]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "def get_topic_2(categories):\n",
    "    labels = []\n",
    "    for category in categories:\n",
    "        x = category['label'].split('/')\n",
    "        labels.append(x[1])\n",
    "    return list(set(labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "dataset_2['topics']=dataset_2['categories'].apply(lambda x: get_topic_2(x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-96-f6ef7e5265d9>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_2['topics']=dataset_2['categories'].apply(lambda x: get_topic_2(x))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "dataset_2[['text', 'categories', 'topics']].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  @Uber_Support hi guys why all my trips this we...   \n",
       "1  So are we getting Uber eats league 1 or not @S...   \n",
       "2  @footballdaily 2-3 years of Messi, a bit of ca...   \n",
       "3  @Prashan32439454 @Uber_Support @rameshjoshi80 ...   \n",
       "4  Uber's Gopuff partnership, Drizly deal being p...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [{'score': 0.693098, 'label': '/travel/special...   \n",
       "1  [{'score': 0.59693, 'label': '/sports/baseball...   \n",
       "2   [{'score': 0.785107, 'label': '/sports/soccer'}]   \n",
       "3  [{'score': 0.685688, 'label': '/science/mathem...   \n",
       "4  [{'score': 0.778195, 'label': '/news'}, {'scor...   \n",
       "\n",
       "                                              topics  \n",
       "0                  [travel, automotive and vehicles]  \n",
       "1                     [food and drink, sports, pets]  \n",
       "2                                           [sports]  \n",
       "3  [science, art and entertainment, style and fas...  \n",
       "4                    [business and industrial, news]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Uber_Support hi guys why all my trips this we...</td>\n",
       "      <td>[{'score': 0.693098, 'label': '/travel/special...</td>\n",
       "      <td>[travel, automotive and vehicles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So are we getting Uber eats league 1 or not @S...</td>\n",
       "      <td>[{'score': 0.59693, 'label': '/sports/baseball...</td>\n",
       "      <td>[food and drink, sports, pets]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@footballdaily 2-3 years of Messi, a bit of ca...</td>\n",
       "      <td>[{'score': 0.785107, 'label': '/sports/soccer'}]</td>\n",
       "      <td>[sports]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Prashan32439454 @Uber_Support @rameshjoshi80 ...</td>\n",
       "      <td>[{'score': 0.685688, 'label': '/science/mathem...</td>\n",
       "      <td>[science, art and entertainment, style and fas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uber's Gopuff partnership, Drizly deal being p...</td>\n",
       "      <td>[{'score': 0.778195, 'label': '/news'}, {'scor...</td>\n",
       "      <td>[business and industrial, news]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuacion, creamos una variable por cada una de las etiquetas en 'topics', es decir, 'topic_1', 'topic_2' y 'topic_3'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "def desagregar_topics(lista_topics, n_topic):\n",
    "    try:\n",
    "        topic = lista_topics[n_topic-1]\n",
    "    except:\n",
    "        topic = 'NA'\n",
    "    return topic"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "dataset_2['topic_1'] = dataset_2['topics'].apply(lambda x: desagregar_topics(x, 1))\n",
    "dataset_2['topic_2'] = dataset_2['topics'].apply(lambda x: desagregar_topics(x, 2))\n",
    "dataset_2['topic_3'] = dataset_2['topics'].apply(lambda x: desagregar_topics(x, 3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-99-63b6f2d20988>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_2['topic_1'] = dataset_2['topics'].apply(lambda x: desagregar_topics(x, 1))\n",
      "<ipython-input-99-63b6f2d20988>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_2['topic_2'] = dataset_2['topics'].apply(lambda x: desagregar_topics(x, 2))\n",
      "<ipython-input-99-63b6f2d20988>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_2['topic_3'] = dataset_2['topics'].apply(lambda x: desagregar_topics(x, 3))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "dataset_2[['text', 'categories', 'topics', 'topic_1', 'topic_2', 'topic_3']].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  @Uber_Support hi guys why all my trips this we...   \n",
       "1  So are we getting Uber eats league 1 or not @S...   \n",
       "2  @footballdaily 2-3 years of Messi, a bit of ca...   \n",
       "3  @Prashan32439454 @Uber_Support @rameshjoshi80 ...   \n",
       "4  Uber's Gopuff partnership, Drizly deal being p...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [{'score': 0.693098, 'label': '/travel/special...   \n",
       "1  [{'score': 0.59693, 'label': '/sports/baseball...   \n",
       "2   [{'score': 0.785107, 'label': '/sports/soccer'}]   \n",
       "3  [{'score': 0.685688, 'label': '/science/mathem...   \n",
       "4  [{'score': 0.778195, 'label': '/news'}, {'scor...   \n",
       "\n",
       "                                              topics                  topic_1  \\\n",
       "0                  [travel, automotive and vehicles]                   travel   \n",
       "1                     [food and drink, sports, pets]           food and drink   \n",
       "2                                           [sports]                   sports   \n",
       "3  [science, art and entertainment, style and fas...                  science   \n",
       "4                    [business and industrial, news]  business and industrial   \n",
       "\n",
       "                   topic_2            topic_3  \n",
       "0  automotive and vehicles                 NA  \n",
       "1                   sports               pets  \n",
       "2                       NA                 NA  \n",
       "3    art and entertainment  style and fashion  \n",
       "4                     news                 NA  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>topics</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Uber_Support hi guys why all my trips this we...</td>\n",
       "      <td>[{'score': 0.693098, 'label': '/travel/special...</td>\n",
       "      <td>[travel, automotive and vehicles]</td>\n",
       "      <td>travel</td>\n",
       "      <td>automotive and vehicles</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So are we getting Uber eats league 1 or not @S...</td>\n",
       "      <td>[{'score': 0.59693, 'label': '/sports/baseball...</td>\n",
       "      <td>[food and drink, sports, pets]</td>\n",
       "      <td>food and drink</td>\n",
       "      <td>sports</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@footballdaily 2-3 years of Messi, a bit of ca...</td>\n",
       "      <td>[{'score': 0.785107, 'label': '/sports/soccer'}]</td>\n",
       "      <td>[sports]</td>\n",
       "      <td>sports</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Prashan32439454 @Uber_Support @rameshjoshi80 ...</td>\n",
       "      <td>[{'score': 0.685688, 'label': '/science/mathem...</td>\n",
       "      <td>[science, art and entertainment, style and fas...</td>\n",
       "      <td>science</td>\n",
       "      <td>art and entertainment</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uber's Gopuff partnership, Drizly deal being p...</td>\n",
       "      <td>[{'score': 0.778195, 'label': '/news'}, {'scor...</td>\n",
       "      <td>[business and industrial, news]</td>\n",
       "      <td>business and industrial</td>\n",
       "      <td>news</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Opcion 3\n",
    "Nos quedamos con todas las etiquetas de la primera categoría. \\\n",
    "\\\n",
    "**Ej.** [{'score': 0.693098, 'label': '/travel/specialty travel/adventure travel'}, {'score': 0.599703, 'label': '/travel/business travel'}, {'score': 0.579002, 'label': '/automotive and vehicles'}]\\\n",
    "--> **Nos quedamos con 'travel', 'specialty travel', 'adventure travel'**\\\n",
    "En este caso, debemos tener tantas columnas como el número máximo de etiquetas en una fila"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "dataset_3 = dataset[:100]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "dataset_3['categories'][0][0]['label']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/travel/specialty travel/adventure travel'"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "def get_topic_3(categories):\n",
    "    x = categories[0]['label']\n",
    "    x = x.split('/')\n",
    "    x.remove('')\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "dataset_3['topics']=dataset_3['categories'].apply(lambda x: get_topic_3(x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-105-c40aaccecc86>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_3['topics']=dataset_3['categories'].apply(lambda x: get_topic_3(x))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "dataset_3['topic_1'] = dataset_3['topics'].apply(lambda x: desagregar_topics(x, 1))\n",
    "dataset_3['topic_2'] = dataset_3['topics'].apply(lambda x: desagregar_topics(x, 2))\n",
    "dataset_3['topic_3'] = dataset_3['topics'].apply(lambda x: desagregar_topics(x, 3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-108-98f2389c8cf2>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_3['topic_1'] = dataset_3['topics'].apply(lambda x: desagregar_topics(x, 1))\n",
      "<ipython-input-108-98f2389c8cf2>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_3['topic_2'] = dataset_3['topics'].apply(lambda x: desagregar_topics(x, 2))\n",
      "<ipython-input-108-98f2389c8cf2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_3['topic_3'] = dataset_3['topics'].apply(lambda x: desagregar_topics(x, 3))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "dataset_3[['text', 'categories', 'topics', 'topic_1', 'topic_2', 'topic_3']].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  \\\n",
       "0  @Uber_Support hi guys why all my trips this we...   \n",
       "1  So are we getting Uber eats league 1 or not @S...   \n",
       "2  @footballdaily 2-3 years of Messi, a bit of ca...   \n",
       "3  @Prashan32439454 @Uber_Support @rameshjoshi80 ...   \n",
       "4  Uber's Gopuff partnership, Drizly deal being p...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [{'score': 0.693098, 'label': '/travel/special...   \n",
       "1  [{'score': 0.59693, 'label': '/sports/baseball...   \n",
       "2   [{'score': 0.785107, 'label': '/sports/soccer'}]   \n",
       "3  [{'score': 0.685688, 'label': '/science/mathem...   \n",
       "4  [{'score': 0.778195, 'label': '/news'}, {'scor...   \n",
       "\n",
       "                                         topics  topic_1           topic_2  \\\n",
       "0  [travel, specialty travel, adventure travel]   travel  specialty travel   \n",
       "1                            [sports, baseball]   sports          baseball   \n",
       "2                              [sports, soccer]   sports            soccer   \n",
       "3            [science, mathematics, arithmetic]  science       mathematics   \n",
       "4                                        [news]     news                NA   \n",
       "\n",
       "            topic_3  \n",
       "0  adventure travel  \n",
       "1                NA  \n",
       "2                NA  \n",
       "3        arithmetic  \n",
       "4                NA  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>topics</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Uber_Support hi guys why all my trips this we...</td>\n",
       "      <td>[{'score': 0.693098, 'label': '/travel/special...</td>\n",
       "      <td>[travel, specialty travel, adventure travel]</td>\n",
       "      <td>travel</td>\n",
       "      <td>specialty travel</td>\n",
       "      <td>adventure travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So are we getting Uber eats league 1 or not @S...</td>\n",
       "      <td>[{'score': 0.59693, 'label': '/sports/baseball...</td>\n",
       "      <td>[sports, baseball]</td>\n",
       "      <td>sports</td>\n",
       "      <td>baseball</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@footballdaily 2-3 years of Messi, a bit of ca...</td>\n",
       "      <td>[{'score': 0.785107, 'label': '/sports/soccer'}]</td>\n",
       "      <td>[sports, soccer]</td>\n",
       "      <td>sports</td>\n",
       "      <td>soccer</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Prashan32439454 @Uber_Support @rameshjoshi80 ...</td>\n",
       "      <td>[{'score': 0.685688, 'label': '/science/mathem...</td>\n",
       "      <td>[science, mathematics, arithmetic]</td>\n",
       "      <td>science</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>arithmetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uber's Gopuff partnership, Drizly deal being p...</td>\n",
       "      <td>[{'score': 0.778195, 'label': '/news'}, {'scor...</td>\n",
       "      <td>[news]</td>\n",
       "      <td>news</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Opcion 4\n",
    "Nos quedamos con todas las etiquetas de cada categoría. \\\n",
    "\\\n",
    "**Ej.** [{'score': 0.693098, 'label': '/travel/specialty travel/adventure travel'}, {'score': 0.599703, 'label': '/travel/business travel'}, {'score': 0.579002, 'label': '/automotive and vehicles'}]\\\n",
    "--> **Nos quedamos con 'travel', 'specialty travel', 'adventure travel', 'travel', 'business travel' 'automotive and vehicles'** (luego eliminamos duplicados)\\\n",
    "En este caso, debemos tener tantas columnas como el número máximo de etiquetas en una fila"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "#Hacemos una copia del dataset original para trabajar con esta opcion\n",
    "dataset_4 = dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}